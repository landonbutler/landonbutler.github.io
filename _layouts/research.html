---
layout: default
---
<div class="home">
    <div style="text-align:center">
        <h1>Anomaly Detection on Hypergraphs</h1>

    </div>
    <p style="hyphens: none">In traditional graphs, edges denote a relationship between two nodes. In hypergraphs, relations are generalized to be between any subset of nodes. This richer definition allows us to more accurately model interactions on social networks, better track the spread of epidemics, and improve the performance of recommendation systems. </p>
    <img src="..\hypergraph.png" draggable="false" class="align-center" style="margin-bottom: 2rem;width: 500px">
    <p style="hyphens: none">Anomaly detection is the process of identifying behavior that is out of the ordinary. My current research centers on developing learning algorithms that will analyze hypergraph data and search for anomalous behavior.</p>
    <hr />
    <div style="text-align:center">
        <h1>Learning Connectivity for Data Distribution in Robot Teams</h1>
        <p style="hyphens: none">
            <a target="_blank" class="sidebarLinks" style="        text-align: center;
        margin-bottom: 1rem;
        font-weight: 600;
" href="https://arxiv.org/pdf/2103.05091.pdf">Paper</a>  |  <a target="_blank" class="sidebarLinks" style="        text-align: center;
        margin-bottom: 1rem;
        font-weight: 600;
" href="https://github.com/landonbutler/Learning-Connectivity">Code</a>  |  <a target="_blank" class="sidebarLinks" style="        text-align: center;
        margin-bottom: 1rem;
        font-weight: 600;
" href="https://www.youtube.com/watch?v=UNBvsPZIudU">Video</a>
        </p>
    </div>

    <p style="hyphens: none">The majority of algorithms for control of multi-robot teams operate under the assumption that low-latency, global state information necessary to coordinate agent actions can readily be disseminated among the team. However, in harsh environments, especially in those with no existing communication infrastructure, robots must form ad-hoc networks, forcing the team to operate in a distributed fashion. To overcome this challenge, we developed a task-agnostic, decentralized, low-latency method for data distribution in ad-hoc networks using Graph Neural Networks (GNN).</p>
    <img src="..\ConnectivityDiagram2.JPG" draggable="false" class="align-center" style="margin-bottom: 2rem;width: 500px">
    <p style="hyphens: none">Our approach enables multi-agent algorithms reliant on global state information to function by ensuring the global information is readily available at each robot. To do this, agents glean information about the topology of the network from packet transmissions and maintain this in a local structured buffer containing the last known information about the agent's counterparts (as can be seen in the below figure). This memory structure is then fed to a GNN running locally which instructs the agent when and where to transmit their latest state information in the presence of interference by other agents also stability compared to task-specific reward functions in problems reliant on low-latency data attempting to concurrently communicate.</p>
    <img src="..\ConnectivityDiagram.JPG" draggable="false" class="align-center" style="margin-bottom: 2rem;width: 500px">
    <p style="hyphens: none">The distributed GNN communication policies were trained via reinforcement learning using the average Age of Information (AoI) as the reward function. We showed that the AoI reward function improves training distribution. Our approach performs favorably compared to industry-standard methods for data distribution such as random flooding and round robin in environments of varying transmission power and team sizes. We also show that the trained policies successfully generalize to larger teams of both static and mobile agents.</p>
</div>

